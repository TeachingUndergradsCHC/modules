{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cudaMem.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h5ZLJeKDnIM"
      },
      "source": [
        "This notebook will set up colab so that you can run the code for the module \"GPU memory hierarchy\" created by the TOUCH project.  (https://github.com/TeachingUndergradsCHC/modules/tree/master/Architecture/gpu_memory_hierarchy).  The initial setup instructions are based on those by an online post by Andrei Nechaev (https://medium.com/@iphoenix179/running-cuda-c-c-in-jupyter-or-how-to-run-nvcc-in-google-colab-663d33f53772).\n",
        "\n",
        "Begin by setting your runtime to use a GPU (Select \"Change runtime type\" in the Runtime menu and choose \"GPU\".)  Then run the first couple of instructions below.  Run them one at a time, waiting for each to finish before beginning the next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHJlc5jODlIG"
      },
      "source": [
        "!git config --global url.\"https://github.com/\".insteadOf git://github.com/\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FavSJfZAFIc_"
      },
      "source": [
        "!sudo ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc\n",
        "!sudo ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp2Xz4O2FPqW"
      },
      "source": [
        "Now you can run CUDA program by preceeding their code with %%cu.  The next cell is an example, a version of \"Hello World\" for CUDA.  Running it is optional, but useful since doing so will show that the installation was successful. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxX8ypeTFozH"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        " \n",
        "__global__ void hello() {\n",
        "   int id = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "   printf(\"Hello from thread %d (%d of block %d)\\n\", id, threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "   hello<<<5,4>>>();  //launch 5 blocks of 4 threads each\n",
        " \n",
        "   cudaDeviceSynchronize();  //make sure kernel completes\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epta_l7pK6Tl"
      },
      "source": [
        "Now you're ready to start working with the matrix multiplication program (below).  You can run this version as-is, which will perform untiled matrix multiplication.  The key method is kernel, which is the kernel that computes the value of one output cell.  Spend some time understanding this code before proceeding to the tiled version (see directions below the code block)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-yhDrPXUyVA"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <cassert>\n",
        "#include <cstdlib>\n",
        "\n",
        "//constants to control the program:\n",
        "#define NTESTS 1           /* # of tests to run */\n",
        "#define TILE_WIDTH 32      /* # of threads in each dimension per block */\n",
        "                           /* #threads per block = TILE_WIDTH * TILE_WIDTH */\n",
        "#define WIDTH 1024         /* matrix dimensions (assumes square matrix) */\n",
        "\n",
        "__global__ void kernel(float* Md, float* Nd, float* Pd, int width) {\n",
        "  //method to run on GPU; called once per element of output matrix\n",
        "\n",
        "  //calculate indices for the element to compute:\n",
        "  int row = blockIdx.y*TILE_WIDTH + threadIdx.y;\n",
        "  int col = blockIdx.x*TILE_WIDTH + threadIdx.x;\n",
        "\n",
        "  if(row >= width || col >= width)  //check that indices are in bounds\n",
        "    return;\n",
        "\n",
        "  float tmp = 0;  //local variable in which to accumulate the answer\n",
        "  for(int k=0; k < width; ++k)\n",
        "    tmp += Md[row*width + k] * Nd[k*width+col];\n",
        "  Pd[row*width+col] =  tmp;\n",
        "}\n",
        "\n",
        "__global__ void tiledkernel(float* Md, float* Nd, float* Pd, int width) {\n",
        "  //method to run on GPU; called once per element of output matrix\n",
        "\n",
        "  //allocate shared memory (shared between all threads of a block) to hold 1 tile of each matrix\n",
        "  __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];  //holds tile sharing row with element\n",
        "  __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];  //holds tile sharing col with element\n",
        "\n",
        "  //set up short names for indices\n",
        "  int bx = blockIdx.x;\n",
        "  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x;\n",
        "  int ty = threadIdx.y;\n",
        "\n",
        "  //calculate indices for the element to compute:\n",
        "  int row = by * TILE_WIDTH + ty;\n",
        "  int col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "  float tmp = 0;  //local variable in which to accumulate the answer\n",
        "\n",
        "  int num_tiles = (width+TILE_WIDTH-1)/TILE_WIDTH;  //width of matrix in tiles (rounded up)\n",
        "  for (int m=0; m < num_tiles; m++) {  //loop over tiles in row and column containing element\n",
        "\n",
        "    //load Mds and Nds; this thread loads value at its postion; other threads in block load other values\n",
        "    //load 0s for values outside the matrix (tiles can be partially in and partially out of matrix)\n",
        "    if (m*TILE_WIDTH + tx < width && row < width)\n",
        "      Mds[ty][tx] = Md[row*width + (m*TILE_WIDTH + tx)];\n",
        "    else\n",
        "      Mds[ty][tx] = 0.0;\n",
        "    if (m*TILE_WIDTH + ty < width && col < width)\n",
        "      Nds[ty][tx] = Nd[(m*TILE_WIDTH + ty) * width + col];\n",
        "    else\n",
        "      Nds[ty][tx] = 0.0;\n",
        "\n",
        "    __syncthreads();  //barrier to wait for other threads before using Mds and Nds\n",
        "\n",
        "    //TODO: Add the contribution of Mds and Nds to tmp\n",
        "\n",
        "    __syncthreads();  //another barrier; wait for all threads to use Mds and Mds before replacing them\n",
        "  }\n",
        "\n",
        "  //put answer into the result matrix\n",
        "  if (row < width && col < width)\n",
        "    Pd[row*width+col] = tmp;\n",
        "}\n",
        "\n",
        "void verify_solution(float *a, float *b, float *c, int N) {\n",
        "  //verify the solution on the CPU\n",
        "\n",
        "  //threshold for matching: (0 ok since all vals are small ints)\n",
        "  float epsilon = 0;\n",
        "\n",
        "  for (int i = 0; i < N; i++) {      //for every column...\n",
        "    for (int j = 0; j < N; j++) {    //for every row in that column\n",
        "      float tmp = 0;\n",
        "      for (int k = 0; k < N; k++) {\n",
        "\t      tmp += a[i * N + k] * b[k * N + j];\n",
        "      }\n",
        "\n",
        "    // Check against the GPU result, throw an error if not equal\n",
        "    assert(fabs(c[i * N + j] - tmp) <= epsilon);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "void check(cudaError_t retVal) {\n",
        "  //takes return value of a CUDA function and checks if it was an error\n",
        "\n",
        "  if(retVal != cudaSuccess) {\n",
        "    if (retVal==cudaErrorInvalidConfiguration)\n",
        "      printf(\"Number of Threads per block is not valid\");\n",
        "    fprintf(stderr, \"ERROR: %s\\n\", cudaGetErrorString(retVal));\n",
        "    exit(1);\n",
        "  }\n",
        "}\n",
        "\n",
        "float runTest(float* M, float* N, float* P, float* Md, float* Nd, float* Pd, int size) {\n",
        "\n",
        "  //allocate timers\n",
        "  cudaEvent_t start;\n",
        "  check(cudaEventCreate(&start));\n",
        "  cudaEvent_t stop;\n",
        "    check(cudaEventCreate(&stop));\n",
        "\n",
        "  //start timer\n",
        "  check(cudaEventRecord(start,0));\n",
        "\n",
        "  //copy data from host to device\n",
        "  check(cudaMemcpy(Md, M, size, cudaMemcpyHostToDevice));\n",
        "  check(cudaMemcpy(Nd, N, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "  //call the kernel\n",
        "  int gridsize = (WIDTH+TILE_WIDTH-1)/TILE_WIDTH;\n",
        "  dim3 dimGrid(gridsize, gridsize);\n",
        "  dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "  kernel<<<dimGrid,dimBlock>>>(Md, Nd, Pd, WIDTH);\n",
        "\n",
        "  //check if kernel encountered an error due to invalid configurations\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  check(err);\n",
        "\n",
        "  //transfer result matrix to the host\n",
        "  check(cudaMemcpy(P, Pd, size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "  //stop timer and store time\n",
        "  check(cudaEventRecord(stop,0));\n",
        "  check(cudaEventSynchronize(stop));\n",
        "  float diff;\n",
        "  check(cudaEventElapsedTime(&diff, start, stop));\n",
        "\n",
        "  //deallocate timers\n",
        "  check(cudaEventDestroy(start));\n",
        "  check(cudaEventDestroy(stop));\n",
        "\n",
        "  //print and return time\n",
        "  printf(\"Time : %f ms\\n\", diff);\n",
        "    return diff;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  float* M;       //input arrays (on host)\n",
        "  float* N;\n",
        "  float* P;       //output array (on host)\n",
        "\n",
        "  float* Md;      //input arrays (on device)\n",
        "  float* Nd;\n",
        "  float* Pd;      //output array (on device)\n",
        "\n",
        "  int size = WIDTH * WIDTH * sizeof(float);  //size of matrix in bytes\n",
        "\n",
        "  //allocate memory\n",
        "  M = (float*) malloc(size);\n",
        "  N = (float*) malloc(size);\n",
        "  P = (float*) malloc(size);\n",
        "  check(cudaMalloc((void**) &Md, size));\n",
        "  check(cudaMalloc((void**) &Nd, size));\n",
        "  check(cudaMalloc((void**) &Pd, size));\n",
        "\n",
        "  //fill M and N arrays (all elements <= 2048 so results stay small)\n",
        "  int cor = 0;\n",
        "  for(int i=0; i < WIDTH * WIDTH; i++){\n",
        "    M[i] = N[i] = i-cor ;\n",
        "    if(i % 2048 == 0)\n",
        "\tcor=i;\n",
        "  }\n",
        "\n",
        "  float total_time = 0;  //accumultate execution times for averaging\n",
        "\n",
        "  for(int i=0; i < NTESTS; i++)\n",
        "    total_time += runTest(M, N, P, Md, Nd, Pd, size);\n",
        "\n",
        "  printf(\"Avg for %d tests: %f ms and size of matrix %d\\n\",\n",
        "         NTESTS, total_time/(float)NTESTS, WIDTH);\n",
        "\n",
        "  verify_solution(M,N,P,WIDTH);  //verify result\n",
        "\n",
        "  //free all memory:\n",
        "  free(M);\n",
        "  free(N);\n",
        "  free(P);\n",
        "  check(cudaFree(Md));\n",
        "  check(cudaFree(Nd));\n",
        "  check(cudaFree(Pd));\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you're ready to convert this to a tiled version of matrix multiplication. The skeleton for this version is already in the file above.  Switch the call to kernel in main to a call to tiledKernel. If you run this version, it will fail a testing assertion.  Go to the TODO comment in tiledKernel and complete this section so that it computes the contribution of the two cached tiles to its cell of the output. Then run the program, which will test whether your implementation gives the correct answer."
      ],
      "metadata": {
        "id": "qHGFRuuTo3Af"
      }
    }
  ]
}