{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amdahl's Law",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeachingUndergradsCHC/modules/blob/master/Fundamentals/elementary_notions/amdahls_law.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEFi0iFlfs1Q"
      },
      "source": [
        "# Amdahl's law\n",
        "\n",
        "In this notebook, we will explore and discuss Amdahl's law."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "# Speed up from parallelism\n",
        "\n",
        "Assume that you have a program that requires 100 seconds to complete. If you can fully parallelize the program how long does it take to run it on two cores?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MhSv1VDXHI6"
      },
      "source": [
        "# execution time with 2 processors\n",
        "100/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqikND1pXXFm"
      },
      "source": [
        "So it will take 50 seconds to run the program on two cores. \n",
        "\n",
        "Let's define speed up (S) as: \n",
        "\n",
        "   $S = \\frac{OldExecutionTime}{NewExecutionTime}$\n",
        "\n",
        "This result in a speed up of S = (old execution time)/(new execution time) = 100/50 = 2. \n",
        "\n",
        "Similarly, if we have 100 cores available, we can run the program in just 1 second (100 seconds/100 cores), resulting in a speed up of 100 (100 second/1 second).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lczQQFNfXNfS"
      },
      "source": [
        "# Speed up from non-fully paralellizable programs\n",
        "\n",
        "If 10% of the program cannot be parallized and have to run sequentially, how long does it take to run it on 2 cores?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm4mNuFEZPRP"
      },
      "source": [
        "# execution time for 2 cores when 10% of the program is serial\n",
        "0.10 * 100 + (1-0.10)*100/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tirqd9eXZjS_"
      },
      "source": [
        "So, when 90% of the program can be parallized, the speed up is now only, S = 100/55 = 1.8. When you have 100 processors, what will the speed up be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgFpwIWLZuIq"
      },
      "source": [
        "# speed up with 2 cores\n",
        "S2 = 100/55\n",
        "\n",
        "# execution time from 100 cores, when 10% of the program is serial\n",
        "E100 = 0.10 * 100 + (1-0.10)*100/100\n",
        "\n",
        "# speed up with 100 cores\n",
        "S100 = 100/(0.10 * 100 + (1-0.10)*100/100)\n",
        "\n",
        "print(\"S2=\", S2, \"\\nE100=\", E100, \"\\nS100=\", S100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU0SAzNjfkXF"
      },
      "source": [
        "As you can see from the calculation above, the speed up is not anywhere near 100x anymore, but it is closer to only 9x. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyOVKvkBauXz"
      },
      "source": [
        "# Amdahl's Law\n",
        "\n",
        "This was observed by Gene Amdahl in the 1960s. He stated that the speed up of a program whose a portion, _p_, of its execution time can be parallized is limited to:\n",
        "\n",
        "$S = \\frac{1}{1-p}$\n",
        "\n",
        "In our case, _p_ was 0.9 (90%), so our speed up is limited to:\n",
        "\n",
        "$S = \\frac{1}{1-0.9} = \\frac{1}{0.1}=10$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g3kV-6Dcq8c"
      },
      "source": [
        "Let's do some experiments to see how much speed up we can get with a thousand cores, 1 million cores, and 1 billion cores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4aRrBZLc_Mh"
      },
      "source": [
        "# execution time with 1 core\n",
        "E1 = 100\n",
        "\n",
        "# a thousand cores\n",
        "E1000 =  0.10 * E1  + (1-0.10)*E1/1000\n",
        "\n",
        "S1000 = E1/E1000\n",
        "\n",
        "# a million cores\n",
        "Emillion =  0.10 * E1  + (1-0.10)*E1/1000000.0\n",
        "\n",
        "Smillion = E1/Emillion\n",
        "\n",
        "# a billion cores\n",
        "Ebillion =  0.10 * E1  + (1-0.10)*E1/1000000000.0\n",
        "\n",
        "Sbillion = E1/Ebillion\n",
        "\n",
        "print(\"S1000=\",S1000)\n",
        "print(\"Smillion=\",Smillion)\n",
        "print(\"Sbillion=\",Sbillion)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NSqFLD-eF6c"
      },
      "source": [
        "So, we're getting closer to 10 but not quite. That will only get reached when we have infinite number of processors. \n",
        "\n",
        "$E_{\\infty} = 0.10 * E1 + \\frac{(1-0.10)*E1}{\\infty}$\n",
        "\n",
        "Since anything divided by infinity is zero, we have $E_{\\infty} = 10$, resulting in a speed up $S = 10$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dGYK4OueTv6"
      },
      "source": [
        "# infinite cores\n",
        "Ebillion =  0.10 * E1  + (1-0.10)*E1/1000000000.0\n",
        "\n",
        "Sbillion = E1/Ebillion\n",
        "print(\"Sbillion=\",Sbillion)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQsB8gL0q62P"
      },
      "source": [
        "If we graph the speed up $S$ versus the number of processors for different number of processors, you'd get the following graphs, similar to the one in the [Wikipedia](https://en.wikipedia.org/wiki/Amdahl%27s_law)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtpPPGdyrh-b"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [7.00, 4.00]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# x-axis values \n",
        "n = [1, 2, 4, 8, 16, 64, 128, 256, 512, 1024] \n",
        "  \n",
        "# Y-axis values is the speed up, calculated using s = 1 / (1-p) + p/n\n",
        "serialPortion = [.5, .75, .9, .95, .99]\n",
        "\n",
        "for p in serialPortion:\n",
        "  y = [] \n",
        "  for x in n:\n",
        "    y.append(1.0/((1.0-p)+p/x))\n",
        "  \n",
        "  ax.plot(n, y, label=str(p)) \n",
        "  \n",
        "leg = plt.legend(loc='upper right')\n",
        "leg.get_frame().set_alpha(0.6)\n",
        "\n",
        "# function to show the plot \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMsgrOFdf3Hf"
      },
      "source": [
        "# Further readings\n",
        "\n",
        "Note that the discussion above is related to a fixed problem size (this is also called _strong scaling_). In many cases, problem sizes scale with the amount of available resources (_weak scaling_). For this another more optimistic law, called Gustafson's law, is more applicable. \n",
        "\n",
        "Here are some references if you'd like to learn more about the topic:\n",
        "\n",
        " 1. [Amdahl's paper from 1967 AFIPS](https://archive.is/o/xOrx3/www.futurechips.org/wp-content/uploads/2011/06/5_amdahl.pdf).\n",
        " 2. [Weak Scaling vs Strong Scaling](https://hpc-wiki.info/hpc/Scaling_tutorial#Strong_or_Weak_Scaling). HPC Wiki."
      ]
    }
  ]
}